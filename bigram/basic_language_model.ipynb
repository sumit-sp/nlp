{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6df611a2-e77b-409b-845a-25ea7f9af572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: matplotlib 3.6.2\n",
      "Uninstalling matplotlib-3.6.2:\n",
      "  Would remove:\n",
      "    c:\\users\\sumitp\\anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib-3.6.2-py3.10-nspkg.pth\n",
      "    c:\\users\\sumitp\\anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib-3.6.2.dist-info\\*\n",
      "    c:\\users\\sumitp\\anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\*\n",
      "    c:\\users\\sumitp\\anaconda3\\envs\\pytorch\\lib\\site-packages\\mpl_toolkits\\axes_grid1\\*\n",
      "    c:\\users\\sumitp\\anaconda3\\envs\\pytorch\\lib\\site-packages\\mpl_toolkits\\axisartist\\*\n",
      "    c:\\users\\sumitp\\anaconda3\\envs\\pytorch\\lib\\site-packages\\mpl_toolkits\\mplot3d\\*\n",
      "    c:\\users\\sumitp\\anaconda3\\envs\\pytorch\\lib\\site-packages\\mpl_toolkits\\tests\\*\n",
      "    c:\\users\\sumitp\\anaconda3\\envs\\pytorch\\lib\\site-packages\\pylab.py\n",
      "  Would not remove (might be manually added):\n",
      "    c:\\users\\sumitp\\anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\_contour.cp310-win_amd64.pyd\n",
      "    c:\\users\\sumitp\\anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\cbook\\deprecation.py\n",
      "    c:\\users\\sumitp\\anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\mpl-data\\images\\matplotlib_128.ppm\n",
      "    c:\\users\\sumitp\\anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\seaborn-bright.mplstyle\n",
      "    c:\\users\\sumitp\\anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\seaborn-colorblind.mplstyle\n",
      "    c:\\users\\sumitp\\anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\seaborn-dark-palette.mplstyle\n",
      "    c:\\users\\sumitp\\anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\seaborn-dark.mplstyle\n",
      "    c:\\users\\sumitp\\anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\seaborn-darkgrid.mplstyle\n",
      "    c:\\users\\sumitp\\anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\seaborn-deep.mplstyle\n",
      "    c:\\users\\sumitp\\anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\seaborn-muted.mplstyle\n",
      "    c:\\users\\sumitp\\anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\seaborn-notebook.mplstyle\n",
      "    c:\\users\\sumitp\\anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\seaborn-paper.mplstyle\n",
      "    c:\\users\\sumitp\\anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\seaborn-pastel.mplstyle\n",
      "    c:\\users\\sumitp\\anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\seaborn-poster.mplstyle\n",
      "    c:\\users\\sumitp\\anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\seaborn-talk.mplstyle\n",
      "    c:\\users\\sumitp\\anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\seaborn-ticks.mplstyle\n",
      "    c:\\users\\sumitp\\anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\seaborn-white.mplstyle\n",
      "    c:\\users\\sumitp\\anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\seaborn-whitegrid.mplstyle\n",
      "    c:\\users\\sumitp\\anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\seaborn.mplstyle\n",
      "Proceed (Y/n)? \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\sumitp\\anaconda3\\envs\\pytorch\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\sumitp\\anaconda3\\envs\\pytorch\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44b95ba0-49a7-4863-8bd0-eb206ce10fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from IPython.display import display\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5396f74f-bc27-455c-9d3a-2407d45cd24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090e16c7-6ac2-49f9-a128-55730462276a",
   "metadata": {},
   "source": [
    "### Steps to build a simple Language Model\n",
    "#### 1. Collect data: save a \"*.txt\" with some text in current folder\n",
    "#### 2. Read and Format data: Get the text data in a variable and format as per requirement\n",
    "#### 3. Convert data into tokens : Tokens can be created at character level or word level or sub-word level\n",
    "#### 4. Get embeddings for tokens : Model does not understand tokens as it is hence need to convert them to some form of numbers/vectors\n",
    "#### 5. Build a basic NN : Keep in mind vocab size and embedding size, when designing network input output size\n",
    "#### 6. Write loop to train this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07057bec-4d31-495e-b39e-a9bb75c2ed12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample text from corpus:\n",
      "The Project Gutenberg eBook of Dorothy and the Wizard in Oz\n",
      "    \n",
      "This ebook is for the use of anyone anywhere in the United States and\n",
      "most other parts of the world at no cost and with almost no restr\n"
     ]
    }
   ],
   "source": [
    "# Data collection\n",
    "\n",
    "with open(\"./data/wizard_of_oz.txt\", 'r', encoding=\"utf-8-sig\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "print(f\"Sample text from corpus:\\n{text[:200]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "539248f2-11c8-402e-b878-dc5ed35d6515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data collection\n",
    "\n",
    "def format_names(input_file, output_file):\n",
    "    formatted_names = []\n",
    "    with open(input_file, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.split(' - ')\n",
    "            if len(parts) == 2:\n",
    "                name = parts[0].strip().lower()\n",
    "                name = re.sub(r'^[^a-zA-Z]*|[^a-zA-Z]*$', '', name)\n",
    "                formatted_names.append(name)\n",
    "\n",
    "    with open(output_file, 'w') as f:\n",
    "        f.write('\\n'.join(formatted_names))\n",
    "\n",
    "# Example usage:\n",
    "input_file = './data/marathi_boy_names.txt'\n",
    "output_file = './data/marathi_names_output.txt'\n",
    "format_names(input_file, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5cf4286-6f82-4733-abde-11fc035d634f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aarv', 'ansh', 'aalok', 'aapt', 'aabheer']\n"
     ]
    }
   ],
   "source": [
    "# Create a loop that reads all the names in \"marathi_names_output.txt\" line by line, \n",
    "# and adds start <s> and end <e> at the starting and ending of each of the name\n",
    "\n",
    "with open(\"./data/marathi_names_output.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.readlines()\n",
    "name_list = []\n",
    "for name in text:\n",
    "    name = name.strip()\n",
    "    name_list.append(name)\n",
    "\n",
    "print(name_list[:5])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64857ff2-658b-4cdb-908b-34ca319019b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mapping of chars and integers\n",
    "sequence = []\n",
    "chars = []\n",
    "for name in name_list:\n",
    "    sequence += [\"<s>\"] + list(name) + [\"<e>\"]\n",
    "sequence.remove(\"/\")\n",
    "vocab = sorted(set(sequence))\n",
    "\n",
    "char_to_idx = {char:idx for idx,char in enumerate(vocab)}\n",
    "idx_to_char = {idx:char for idx,char in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb1b2484-4ab1-45cc-8355-e3b84dbddb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let us create the Bigrams out of list of names\n",
    "bigram = []\n",
    "for i in range(len(sequence)- 1):\n",
    "    ch1 = sequence[i]\n",
    "    ch2 = sequence[i+1]\n",
    "    bigram.append(tuple([ch1,ch2]))\n",
    "bigram = list(filter(lambda x: x != ('<e>', '<s>') , bigram))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8474de5e-20ac-4c62-abf3-2ec5e79b5261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3534\n",
      "[('<s>', 'a'), ('a', 'a'), ('a', 'r'), ('r', 'v'), ('v', '<e>'), ('<s>', 'a'), ('a', 'n'), ('n', 's'), ('s', 'h'), ('h', '<e>')]\n"
     ]
    }
   ],
   "source": [
    "print(len(bigram))\n",
    "print(bigram[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1386a9c2-2bd2-4dbc-8239-def834b897cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique occurences of bigrams: 290\n"
     ]
    }
   ],
   "source": [
    "bigram_count = {}\n",
    "\n",
    "#Iterate over unique items in bigram list and count their occurance\n",
    "for item in set(bigram):\n",
    "    bigram_count[item] = bigram.count(item)\n",
    "bigram_count = sorted(bigram_count.items(), key=lambda x: x[1], reverse= True)\n",
    "\n",
    "print(f\"Number of unique occurences of bigrams: {len(bigram_count)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44ff0d6b-d4b2-4b7e-8484-fb39805b156f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_matrix = torch.zeros((len(vocab), len(vocab)), dtype = torch.int32)\n",
    "\n",
    "for item in bigram_count:\n",
    "    ch1 = item[0][0]\n",
    "    ch1_idx = char_to_idx[ch1]\n",
    "    ch2 = item[0][1]\n",
    "    ch2_idx = char_to_idx[ch2]\n",
    "    bigram_matrix[ch1_idx][ch2_idx] = item[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1569d731-977b-40c2-8220-3724ff219d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25, 25])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_matrix.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4db5932-0d44-4987-bfa6-630160d3d558",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "numpy_array = bigram_matrix.to('cpu').numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ce850a8-612d-4e23-8b9c-b234e569deab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 25)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2a570ae-911e-4334-a753-b0fc7acc650a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "     ------------------------------------ 294.9/294.9 kB 109.7 kB/s eta 0:00:00\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\sumitp\\anaconda3\\envs\\pytorch\\lib\\site-packages (from seaborn) (1.5.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\sumitp\\anaconda3\\envs\\pytorch\\lib\\site-packages (from seaborn) (1.24.1)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\sumitp\\anaconda3\\envs\\pytorch\\lib\\site-packages (from seaborn) (3.6.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\sumitp\\anaconda3\\envs\\pytorch\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\sumitp\\anaconda3\\envs\\pytorch\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\sumitp\\anaconda3\\envs\\pytorch\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.0.9)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\sumitp\\anaconda3\\envs\\pytorch\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (9.3.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\sumitp\\anaconda3\\envs\\pytorch\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.38.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\sumitp\\anaconda3\\envs\\pytorch\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.0.6)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\sumitp\\anaconda3\\envs\\pytorch\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sumitp\\anaconda3\\envs\\pytorch\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (23.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sumitp\\anaconda3\\envs\\pytorch\\lib\\site-packages (from pandas>=1.2->seaborn) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sumitp\\anaconda3\\envs\\pytorch\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\sumitp\\anaconda3\\envs\\pytorch\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\sumitp\\anaconda3\\envs\\pytorch\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\sumitp\\anaconda3\\envs\\pytorch\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\sumitp\\anaconda3\\envs\\pytorch\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\sumitp\\anaconda3\\envs\\pytorch\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\sumitp\\anaconda3\\envs\\pytorch\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\sumitp\\anaconda3\\envs\\pytorch\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77e38d1-401e-43af-958f-5382a58c22fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Plot using Seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(numpy_array, cmap='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea739cbb-fb6f-4465-b420-a33b39b08a9a",
   "metadata": {},
   "source": [
    "##### In NLP tokens refers to the total number of \"words\" in your corpus. The vocab is the number of unique \"words\".\n",
    "##### It should be the case that vocab <= tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "40d10d55-6844-469e-96c5-e6844a9256e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'project', 'gutenberg', 'ebook', 'of', 'dorothy', 'and', 'the', 'wizard', 'in', 'oz', 'this', 'ebook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere', 'in', 'the', 'united', 'states', 'and', 'most', 'other', 'parts', 'of', 'the']\n",
      "Total number of tokens: 42287\n",
      "vocabulary size: 4331\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_words(word_list):\n",
    "    cleaned_words = []\n",
    "    for word in word_list:\n",
    "        cleaned_word = re.sub(r'^[^a-zA-Z]*|[^a-zA-Z]*$', '', word)\n",
    "        if cleaned_word:  # Check if the word is not empty after cleaning\n",
    "            cleaned_words.append(cleaned_word)\n",
    "    return cleaned_words\n",
    "\n",
    "tokens = text.lower().strip().split()\n",
    "tokens = clean_words(tokens)\n",
    "print(tokens[:30])\n",
    "print(f\"Total number of tokens: {len(tokens)}\")\n",
    "\n",
    "vocab = sorted(set(tokens))\n",
    "print(f\"vocabulary size: {len(vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d925b6e4-1996-4cb5-ac41-c39834e7ee47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: [['the', 'project'], ['project', 'gutenberg'], ['gutenberg', 'ebook'], ['ebook', 'of']]\n",
      "target: ['gutenberg', 'ebook', 'of', 'dorothy']\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Data Preparation\n",
    "\n",
    "# Decide on the sequence length (e.g., bi-grams, tri-grams)\n",
    "sequence_length = 2  # For bi-grams\n",
    "# Create input-output pairs for training\n",
    "input_sequences = [tokens[i:i+sequence_length] for i in range(len(tokens) - sequence_length)]\n",
    "target_outputs = [tokens[i+sequence_length] for i in range(len(tokens) - sequence_length)]\n",
    "\n",
    "print(f\"input: {input_sequences[:4]}\")\n",
    "print(f\"target: {target_outputs[:4]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "de17f356-4cbe-4029-a32a-a98153fc5b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Tokenization\n",
    "# Create a vocabulary mapping each unique token to a numerical ID\n",
    "vocab = {token: i for i, token in enumerate(set(tokens))}\n",
    "\n",
    "# Convert tokens to numerical IDs\n",
    "input_sequences_ids = [[vocab[token] for token in sequence] for sequence in input_sequences]\n",
    "target_outputs_ids = [vocab[token] for token in target_outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0456dcaf-6881-49ec-b74e-9e540af23db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['my', 'name', 'is', 'dorothy']\n",
      "('dorothy',)\n",
      "dorothy and the project gutenberg ebook of dorothy and the project gutenberg ebook of dorothy and the project gutenberg ebook of dorothy and the project gutenberg ebook of dorothy and the project gutenberg ebook of dorothy and the project gutenberg ebook of dorothy and the project gutenberg ebook of dorothy and the project gutenberg ebook of dorothy and the project gutenberg ebook of dorothy and the project gutenberg ebook of dorothy and the project gutenberg ebook of dorothy and the project gutenberg ebook of dorothy and the project gutenberg ebook of dorothy and the project gutenberg ebook of dorothy and the\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Model Building\n",
    "# Define a simple n-gram language model\n",
    "from collections import defaultdict\n",
    "# from nltk.tokenize import word_tokenize\n",
    "\n",
    "class NGramLanguageModel:\n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "        self.ngrams = defaultdict(list)\n",
    "\n",
    "    def train(self, tokens):\n",
    "        # tokens = word_tokenize(corpus)\n",
    "        for i in range(len(tokens) - self.n + 1):\n",
    "            ngram = tuple(tokens[i:i+self.n])\n",
    "            self.ngrams[ngram[:-1]].append(ngram[-1])\n",
    "\n",
    "    def generate_text(self, input_string, num_words=50):\n",
    "        tokens = input_string.lower().strip().split()\n",
    "        tokens = clean_words(tokens)\n",
    "        print(tokens)\n",
    "        seed = tuple(tokens)[-self.n+1:]\n",
    "        print(seed)\n",
    "        result = list(seed)\n",
    "        for _ in range(num_words):\n",
    "            last_n_words = tuple(result[-self.n+1:])\n",
    "            next_word = self._get_next_word(last_n_words)\n",
    "            if next_word:\n",
    "                result.append(next_word)\n",
    "            else:\n",
    "                break\n",
    "        return ' '.join(result)\n",
    "\n",
    "    def _get_next_word(self, ngram_prefix):\n",
    "        possible_next_words = self.ngrams.get(ngram_prefix, [])\n",
    "        if possible_next_words:\n",
    "            return possible_next_words[0]  # Just return the first next word for simplicity\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def _get_random_seed(self):\n",
    "        # Return a random seed from the available n-grams\n",
    "        return next(iter(self.ngrams.keys()))\n",
    "\n",
    "# Example usage:\n",
    "corpus = \"The quick brown fox jumps over the lazy dog\"\n",
    "n = 2\n",
    "model = NGramLanguageModel(n)\n",
    "model.train(tokens)\n",
    "generated_text = model.generate_text(input_string=\"my name is dorothy\",num_words= 100)\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "eaf6a82a-7d9b-4feb-bb0b-a2e5e2b1868e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0], dtype=torch.int32)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(5, dtype = torch.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8452909b-5275-452d-83ce-0bb77d1e42a3",
   "metadata": {},
   "source": [
    "##### Now we have the tokens but for training the model we will need to convert each token to vectors aka Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ba29e3ad-944a-4831-99c8-88229b4d7d17",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "embedding(): argument 'indices' (position 2) must be Tensor, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m embedding \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mEmbedding(num_embeddings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(tokens), embedding_dim\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m token_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\sparse.py:160\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py:2210\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2204\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2205\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2206\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2207\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2208\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2209\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: embedding(): argument 'indices' (position 2) must be Tensor, not list"
     ]
    }
   ],
   "source": [
    "embedding = nn.Embedding(num_embeddings=len(tokens), embedding_dim= 8)\n",
    "token_embeddings = embedding(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71be073c-e499-453b-b3a6-5bc9134b3ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing trial_file.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile trial_file.py\n",
    "\n",
    "import argparse\n",
    "\n",
    "def addition(a, b):\n",
    "    return a+b\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--a\", type = int, default= 0)\n",
    "    parser.add_argument(\"--b\", type = int, default= 0)\n",
    "    args = parser.parse_args()\n",
    "    a = args.a\n",
    "    b = args.b\n",
    "    c = addition(a, b)\n",
    "    print(f\"sum of given to nos. is {c}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5cf5dddc-0861-4002-be15-4559bb9b94bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum of given to nos. is 13\n"
     ]
    }
   ],
   "source": [
    "%run trial_file.py --a 6 --b 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7346a9d-61e7-407f-a11d-c9844dae83a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%mkdir python_scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "461bb873-ff71-4843-b383-483fa1b3b01d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum of given to nos. is 571889\n",
      "CPU times: total: 15.6 ms\n",
      "Wall time: 3.02 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%run trial_file.py --a 2890 --b 568999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a00216f-36a5-4c91-8a24-0e0334409f7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
